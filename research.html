<html lang="en-US"><head>
    
<style>
 
.center {
 text-align: center
}
 
</style>
    
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Japanese Linguist Software Engineer | Matthew Bieda</title>
<meta name="generator" content="Jekyll v3.9.0">
<meta property="og:title" content="Japanese Linguist Software Engineer">
<meta property="og:locale" content="en_US">
<meta name="description" content="Created for my CS50x final project.">
<meta property="og:description" content="Created for my CS50x final project.">
<link rel="canonical" href="https://matthewbieda.github.io/">
<meta property="og:url" content="https://matthewbieda.github.io/">
<meta property="og:site_name" content="Matthew Bieda">
<script type="application/ld+json">
{"@type":"WebSite","headline":"Japanese Linguist Software Engineer","url":"https://matthewbieda.github.io/","description":"Created for my CS50x final project.","name":"Matthew Bieda","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="/assets/css/style.css?v=3480b759b1c98989742c6797e5d49c733b167806">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Machine Translation</h1>
      <h2 class="project-tagline">A historical overview.</h2>
      
      
    </section>

    <section class="main-content">
        <h2 class="center">Rule-Based Machine Translation (RBMT)</h2>
        
        RBMT was the first organized attempt to use computers for the task of the translation around the 1950s, largely driven by the Cold War. It involves the creation of a bilingual dictionary and a set of grammar rules for each language to refer to during translation. In practice, RBMT was underwhelming, failing to produce fluent translations. Also, the initial cost in terms of funding and time to create these systems was very large. This led to the ALPAC report of 1966, which heavily criticized machine translation and led to a large reduction in US government funding. 

        <h2 class="center">Statistical Machine Translation (SMT)</h2>
        
        SMT was pioneered by IBM in the 1990s. It involves the statistical analysis of parallel corpora to derive an approximated translation model (Brown, et al 1990). It has been rather successful and was the dominant approach in machine translation until the emergence of NMT in the last few years. Due to the inclusion of a monolingual language model which quantifies the likelihood of a translation, SMT produced more fluent translations than RBMT. Also, it did not require complicated linguistic rules which were expensive and time consuming to create. However, it did require lots of manual feature engineering to create the representative statistical models. 

        <h2 class="center">Neural Machine Translation (NMT)</h2>
        
        NMT has evolved commensurately with the Deep Learning revolution of the previous decade due to the increase in data availability and the decrease in GPU compute cost that has made the training of these deep sequence-to-sequence models viable. With NMT the complexity lies in the creation and optimization of the neural network architecture. Once established, all translation researchers must do is feed in appropriately pre-processed data and evaluate the output. 

        <h2 class="center">Open NMT and my research</h2>

        OpenNMT is an open source ecosystem for neural machine translation and neural sequence learning. My project aims to build a bilingual Japanese --> English translation system leveraging OpenNMT and my linguistic knowledge and compare it to industry leading MNMT (multilingual NMT) software such as Google Translate and DeepL using the RIBES evaluation metric. This is to evaluate a proprietary vs. open source implementation and to study the effects of a bilingual vs. multilingual model on a high-resource language such as Japanese. My project will be published as a website featuring live JP <-> EN translation and links to my research paper and parallel corpora. 


        
<p><a href="index.html">Homepage</a></p>

    </section>



</body></html>

